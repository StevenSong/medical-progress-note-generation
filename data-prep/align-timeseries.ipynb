{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dpath(fname):\n",
    "    return os.path.join('/mnt/data1/mimic/iii', fname)\n",
    "\n",
    "def cleaned(fname):\n",
    "    return os.path.join('/mnt/data1/mimic/iii/cleaned', fname)\n",
    "\n",
    "def aligned(fname):\n",
    "    return os.path.join('/mnt/data1/mimic/iii/aligned', fname)\n",
    "\n",
    "def filter_encs(df, encs):\n",
    "    return df[df['HADM_ID'].isin(set(encs))].reset_index(drop=True)\n",
    "\n",
    "def filter_pts(df, pts):\n",
    "    return df[df['SUBJECT_ID'].isin(set(pts))].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = pd.read_csv(cleaned('Progress_Notes.csv'), parse_dates=['CHARTTIME'])\n",
    "note_encs = set(notes['HADM_ID'])\n",
    "note_pts = set(notes['SUBJECT_ID'])\n",
    "\n",
    "feat_names  = [\n",
    "    ('HR', ['HR']),\n",
    "    ('BP', ['SBP', 'DBP']),\n",
    "    ('RR', ['RR']),\n",
    "    ('SpO2', ['SpO2']),\n",
    "    ('GCS', ['GCS']),\n",
    "]\n",
    "feats = {k: filter_encs(pd.read_csv(cleaned(f'{k}.csv'), parse_dates=['CHARTTIME']), note_encs) for k, _ in feat_names}\n",
    "\n",
    "adt = filter_encs(pd.read_csv(dpath('ADMISSIONS.csv.gz'), parse_dates=['ADMITTIME', 'DISCHTIME', 'DEATHTIME']), note_encs)\n",
    "patients = filter_pts(pd.read_csv(dpath('PATIENTS.csv.gz'), parse_dates=['DOB', 'DOD', 'DOD_HOSP', 'DOD_SSN']), note_pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{k: len(df) for k, df in feats.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(note_encs) == len(set(adt['HADM_ID']))\n",
    "assert len(note_pts) == len(set(patients['SUBJECT_ID']))\n",
    "print(f\"#Pts: {len(note_pts)} #Encs: {len(note_encs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"#Total_Notes: {len(notes)}\")\n",
    "print(f\"#Unique_Notes: {len(notes.drop_duplicates(subset=['HADM_ID', 'CHARTTIME']))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(notes.drop_duplicates(subset=['HADM_ID', 'CHARTTIME'])['CHARTTIME'].dt.round('H').dt.hour, bins=np.arange(25))\n",
    "plt.title('Progress Note Time of Day')\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Hour')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Align Timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in feats.values():\n",
    "    df.sort_values(['SUBJECT_ID', 'HADM_ID', 'CHARTTIME'], ascending=True, inplace=True)\n",
    "    df['next15'] = df['CHARTTIME'].dt.ceil(\"15min\")\n",
    "    df.drop_duplicates(subset=['HADM_ID', 'next15'], keep=\"last\", inplace=True)\n",
    "\n",
    "notes['next15'] = notes['CHARTTIME'].dt.ceil(\"15min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_window = pd.Timedelta(\"2D\")\n",
    "window_idx = pd.timedelta_range(start=\"0D\", end=rel_window, freq=\"15min\", closed=\"left\")[::-1]\n",
    "window_idx.name = \"Time to note\"\n",
    "data = []\n",
    "for enc in tqdm(note_encs):\n",
    "    pt_notes = notes[notes['HADM_ID'] == enc]\n",
    "    pt_feats = {k: v[v['HADM_ID'] == enc] for k, v in feats.items()}\n",
    "    subj = pt_notes['SUBJECT_ID'].iloc[0]\n",
    "\n",
    "    note_times = pt_notes['next15'].drop_duplicates().sort_values().to_list()\n",
    "    for i, (start_time, end_time) in enumerate(zip([pd.Timestamp('1500')]+note_times[:-1], note_times)):\n",
    "        note_feats = pd.DataFrame(index=window_idx, columns=[col if len(cols) > 1 else k for k, cols in feat_names for col in cols])\n",
    "        for k, cols in feat_names:\n",
    "            v = pt_feats[k]\n",
    "            before_note = v['next15'].between(start_time, end_time, inclusive='right')\n",
    "            note_feat = v[before_note]\n",
    "            time_to_note = end_time - note_feat['next15']\n",
    "            in_window = time_to_note < rel_window\n",
    "            time_to_note = time_to_note[in_window]\n",
    "            for col in cols:\n",
    "                vals = note_feat.loc[in_window, col]\n",
    "                vals.index = time_to_note\n",
    "                note_feats.loc[time_to_note, col if len(cols) > 1 else k] = vals\n",
    "        note_dupes = pt_notes.loc[pt_notes['next15'] == end_time, 'TEXT']\n",
    "        note_dupes.to_csv(aligned(f'notes/{subj}-{enc}-{i}.csv'), index=False)\n",
    "        note_feats.to_csv(aligned(f'feats/{subj}-{enc}-{i}.csv'))\n",
    "        data.append((subj, enc, i, end_time))\n",
    "all_records = pd.DataFrame(data, columns=['SUBJECT_ID', 'HADM_ID', 'NOTE_NUM', 'ALIGNED_TIME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_records['DOD'] = patients.set_index('SUBJECT_ID').loc[all_records['SUBJECT_ID'], 'DOD'].reset_index(drop=True)\n",
    "all_records['TIME_TO_DEATH'] = all_records['DOD'] - all_records['ALIGNED_TIME'].dt.floor(\"1D\")\n",
    "all_records['60D_MORTALITY'] = (all_records['TIME_TO_DEATH'] < pd.Timedelta('60D')).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_records['60D_MORTALITY'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_records['60D_MORTALITY'].value_counts() / len(all_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "temp = all_records['SUBJECT_ID'].drop_duplicates().sample(frac=1, random_state=0).reset_index(drop=True)\n",
    "pt_split = pd.DataFrame({\n",
    "    'SUBJECT_ID': temp,\n",
    "    'SPLIT': [i % n_splits for i in range(len(temp))],\n",
    "})\n",
    "all_records['SPLIT'] = pt_split.set_index('SUBJECT_ID').loc[all_records['SUBJECT_ID']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_records['SPLIT'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_records.groupby('SPLIT')['60D_MORTALITY'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_records.groupby('SPLIT')['60D_MORTALITY'].value_counts() / all_records['SPLIT'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_records.to_csv(aligned('all_records.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_records = pd.read_csv(aligned('all_records.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_records = all_records.drop('DOD', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = all_records.merge(patients, on='SUBJECT_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients['GENDER'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged['GENDER'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "((pd.to_datetime(merged['ALIGNED_TIME']).dt.date - pd.to_datetime(merged['DOB']).dt.date) / timedelta(days=365)).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medpng",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
